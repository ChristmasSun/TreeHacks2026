<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Tutor</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500&display=swap');

    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: #000;
      color: white;
      height: 100vh;
      display: flex;
      flex-direction: column;
    }

    /* Glass utility */
    .glass {
      background: rgba(255, 255, 255, 0.06);
      backdrop-filter: blur(20px);
      -webkit-backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.1);
    }

    /* Shimmer animation */
    @keyframes shimmer {
      0% { background-position: -200% 0; }
      100% { background-position: 200% 0; }
    }

    .header {
      padding: 12px 16px;
      background: rgba(255, 255, 255, 0.04);
      backdrop-filter: blur(20px);
      -webkit-backdrop-filter: blur(20px);
      display: flex;
      justify-content: space-between;
      align-items: center;
      border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    }
    .header h1 {
      font-size: 14px;
      font-weight: 300;
      letter-spacing: 0.025em;
      color: rgba(255, 255, 255, 0.7);
    }
    .close-btn {
      background: none;
      border: none;
      color: white;
      opacity: 0.4;
      cursor: pointer;
      font-size: 20px;
      padding: 4px 8px;
      border-radius: 8px;
      transition: all 0.2s;
    }
    .close-btn:hover { opacity: 0.8; background: rgba(255, 255, 255, 0.06); }
    .main {
      flex: 1;
      display: flex;
      gap: 16px;
      padding: 16px;
      overflow: hidden;
    }
    .video-container {
      flex: 1;
      background: rgba(255, 255, 255, 0.03);
      border-radius: 16px;
      overflow: hidden;
      position: relative;
      min-height: 300px;
      border: 1px solid rgba(255, 255, 255, 0.08);
    }
    #avatar-video {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    .loading, .error {
      position: absolute;
      inset: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      background: rgba(0, 0, 0, 0.4);
      backdrop-filter: blur(10px);
    }
    .spinner {
      width: 40px;
      height: 40px;
      border: 2px solid rgba(96, 165, 250, 0.2);
      border-top-color: #60a5fa;
      border-radius: 50%;
      animation: spin 1s linear infinite;
    }
    @keyframes spin { to { transform: rotate(360deg); } }
    .loading p, .error p {
      margin-top: 12px;
      opacity: 0.6;
      font-size: 14px;
      font-weight: 300;
    }
    .error { color: rgba(248, 113, 113, 0.8); }
    .retry-btn {
      margin-top: 16px;
      padding: 8px 16px;
      background: rgba(59, 130, 246, 0.2);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 12px;
      color: #93c5fd;
      cursor: pointer;
      font-size: 14px;
      transition: all 0.2s;
    }
    .retry-btn:hover {
      background: rgba(59, 130, 246, 0.3);
    }
    .chat {
      width: 300px;
      display: flex;
      flex-direction: column;
      background: rgba(255, 255, 255, 0.06);
      backdrop-filter: blur(20px);
      -webkit-backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 16px;
      overflow: hidden;
    }
    .messages {
      flex: 1;
      overflow-y: auto;
      padding: 12px;
    }
    .message {
      margin-bottom: 8px;
      padding: 8px 12px;
      border-radius: 12px;
      max-width: 85%;
      font-size: 14px;
      font-weight: 300;
    }
    .message.student {
      background: rgba(59, 130, 246, 0.3);
      border: 1px solid rgba(59, 130, 246, 0.2);
      margin-left: auto;
    }
    .message.avatar {
      background: rgba(255, 255, 255, 0.06);
      border: 1px solid rgba(255, 255, 255, 0.08);
    }
    .input-area {
      padding: 12px;
      border-top: 1px solid rgba(255, 255, 255, 0.08);
      display: flex;
      gap: 8px;
    }
    .input-area input {
      flex: 1;
      background: rgba(255, 255, 255, 0.04);
      border: 1px solid rgba(255, 255, 255, 0.08);
      border-radius: 12px;
      padding: 8px 12px;
      color: white;
      font-size: 14px;
      font-family: inherit;
      font-weight: 300;
      transition: all 0.2s;
    }
    .input-area input:focus {
      outline: none;
      border-color: rgba(96, 165, 250, 0.6);
      box-shadow: 0 0 0 1px rgba(96, 165, 250, 0.2);
    }
    .input-area button {
      padding: 8px 16px;
      background: rgba(59, 130, 246, 0.2);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 12px;
      color: #93c5fd;
      cursor: pointer;
      font-family: inherit;
      font-size: 14px;
      transition: all 0.2s;
    }
    .input-area button:hover { background: rgba(59, 130, 246, 0.3); }
    .input-area button:disabled {
      background: rgba(255, 255, 255, 0.04);
      border-color: rgba(255, 255, 255, 0.06);
      color: rgba(255, 255, 255, 0.3);
      cursor: not-allowed;
    }
    .mic-btn {
      padding: 8px 12px;
      background: rgba(255, 255, 255, 0.06);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 12px;
      color: white;
      cursor: pointer;
      font-size: 18px;
      transition: all 0.2s;
    }
    .mic-btn:hover { background: rgba(255, 255, 255, 0.1); }
    .mic-btn.recording {
      background: rgba(59, 130, 246, 0.2);
      border-color: rgba(59, 130, 246, 0.3);
      animation: pulse-mic 1.5s ease-in-out infinite;
    }
    .mic-btn:disabled { opacity: 0.5; cursor: not-allowed; }
    @keyframes pulse-mic {
      0%, 100% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.3); }
      50% { box-shadow: 0 0 0 8px rgba(59, 130, 246, 0); }
    }
    .hidden { display: none !important; }
    .mode-toggle {
      display: flex;
      gap: 4px;
      padding: 4px;
      background: rgba(255, 255, 255, 0.04);
      border-radius: 12px;
      margin-bottom: 12px;
    }
    .mode-btn {
      flex: 1;
      padding: 8px 12px;
      border: none;
      border-radius: 10px;
      background: transparent;
      color: rgba(255, 255, 255, 0.4);
      cursor: pointer;
      font-size: 12px;
      font-family: inherit;
      font-weight: 300;
      transition: all 0.2s;
    }
    .mode-btn.active {
      background: rgba(59, 130, 246, 0.2);
      border: 1px solid rgba(59, 130, 246, 0.2);
      color: #93c5fd;
    }
    .mode-btn:hover:not(.active) { background: rgba(255, 255, 255, 0.06); }
    .speaking-indicator {
      position: absolute;
      bottom: 12px;
      left: 12px;
      background: rgba(255, 255, 255, 0.06);
      backdrop-filter: blur(20px);
      -webkit-backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.1);
      padding: 6px 14px;
      border-radius: 20px;
      font-size: 12px;
      font-weight: 300;
      display: flex;
      align-items: center;
      gap: 8px;
      color: rgba(255, 255, 255, 0.6);
    }
    .speaking-dots {
      display: flex;
      gap: 3px;
    }
    .speaking-dots span {
      width: 6px;
      height: 6px;
      background: #60a5fa;
      border-radius: 50%;
      animation: pulse 1s infinite;
    }
    .speaking-dots span:nth-child(2) { animation-delay: 0.1s; }
    .speaking-dots span:nth-child(3) { animation-delay: 0.2s; }
    @keyframes pulse {
      0%, 100% { opacity: 0.4; transform: scale(0.8); }
      50% { opacity: 1; transform: scale(1); }
    }
    /* Explainer video overlay */
    .explainer-overlay {
      position: absolute;
      inset: 0;
      background: rgba(0, 0, 0, 0.85);
      backdrop-filter: blur(10px);
      -webkit-backdrop-filter: blur(10px);
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      z-index: 100;
    }
    .explainer-overlay.hidden { display: none; }
    .explainer-header {
      padding: 12px 20px;
      text-align: center;
    }
    .explainer-header h2 {
      font-size: 18px;
      font-weight: 300;
      letter-spacing: 0.025em;
      margin-bottom: 4px;
    }
    .explainer-header p {
      font-size: 14px;
      opacity: 0.5;
      font-weight: 300;
    }
    #explainer-video {
      max-width: 100%;
      max-height: calc(100% - 100px);
      border-radius: 16px;
      border: 1px solid rgba(255, 255, 255, 0.08);
    }
    .explainer-controls {
      padding: 12px 20px;
      display: flex;
      gap: 12px;
    }
    .explainer-btn {
      padding: 8px 20px;
      border: none;
      border-radius: 12px;
      cursor: pointer;
      font-size: 14px;
      font-family: inherit;
      font-weight: 400;
      transition: all 0.2s;
    }
    .explainer-btn.primary {
      background: rgba(59, 130, 246, 0.2);
      border: 1px solid rgba(59, 130, 246, 0.2);
      color: #93c5fd;
    }
    .explainer-btn.primary:hover { background: rgba(59, 130, 246, 0.3); }
    .explainer-btn.secondary {
      background: rgba(255, 255, 255, 0.06);
      border: 1px solid rgba(255, 255, 255, 0.1);
      color: rgba(255, 255, 255, 0.6);
    }
    .explainer-btn.secondary:hover { background: rgba(255, 255, 255, 0.1); }
  </style>
</head>
<body>
  <div class="header">
    <h1>AI Tutor &bull; <span id="student-name">Student</span></h1>
    <button class="close-btn" onclick="closeWindow()">&times;</button>
  </div>

  <div class="main">
    <div class="video-container">
      <div class="loading" id="loading">
        <div class="spinner"></div>
        <p>Starting AI Tutor...</p>
      </div>
      <div class="error hidden" id="error">
        <p>Connection Error</p>
        <p id="error-msg"></p>
        <button class="retry-btn" onclick="startAvatar()">Retry</button>
      </div>
      <video id="avatar-video" autoplay playsinline></video>
      <!-- Explainer video overlay for quiz -->
      <div class="explainer-overlay hidden" id="explainer-overlay">
        <div class="explainer-header">
          <h2 id="explainer-title">Explainer Video</h2>
          <p id="explainer-concept">Watch to learn more about this concept</p>
        </div>
        <video id="explainer-video" controls></video>
        <div class="explainer-controls">
          <button class="explainer-btn secondary" onclick="skipExplainer()">Skip</button>
          <button class="explainer-btn primary hidden" id="continue-btn" onclick="continueAfterExplainer()">Continue Quiz</button>
        </div>
      </div>
      <div class="speaking-indicator hidden" id="speaking">
        <div class="speaking-dots">
          <span></span><span></span><span></span>
        </div>
        <span>Speaking...</span>
      </div>
    </div>

    <div class="chat">
      <div class="mode-toggle">
        <div id="voice-status" class="mode-btn active" style="flex:1; cursor:default; text-align:center;">
          üé§ Always Listening
        </div>
      </div>
      <div class="messages" id="messages"></div>
      <div class="input-area" id="tutor-input">
        <button id="mic-btn" class="mic-btn recording" onclick="toggleMic()" title="Mute/Unmute">üé§</button>
        <input type="text" id="input" placeholder="üé§ Listening..." disabled>
        <button id="send-btn" onclick="sendMessage()" disabled>Send</button>
      </div>
    </div>
  </div>

  <script type="module">
    import StreamingAvatar, { AvatarQuality, StreamingEvents } from 'https://esm.sh/@heygen/streaming-avatar@latest';

    let avatar = null;
    let sessionId = null;
    let conversationHistory = [];

    // Track whether current speech was interrupted by user
    let _wasInterrupted = false;

    /**
     * Speak text through HeyGen avatar using async mode.
     * Completion is handled by AVATAR_STOP_TALKING event, not by awaiting.
     */
    async function avatarSpeak(text) {
      _wasInterrupted = false;
      // Interrupt any current speech first
      try { await avatar.interrupt(); } catch(e) {}

      console.log('üîä avatarSpeak:', text.slice(0, 60));
      try {
        await avatar.speak({
          text,
          taskType: 'repeat',
          taskMode: 'async',
        });
      } catch (e) {
        console.error('Avatar speak error:', e);
      }
      // Don't wait for completion ‚Äî AVATAR_STOP_TALKING event handles it
    }

    const params = new URLSearchParams(window.location.search);
    const studentName = params.get('name') || 'Student';
    const backendUrl = params.get('backend') || 'http://127.0.0.1:8000';

    document.getElementById('student-name').textContent = studentName;

    window.closeWindow = function() {
      if (avatar) avatar.stopAvatar().catch(() => {});
      window.close();
    }

    function showLoading() {
      document.getElementById('loading').classList.remove('hidden');
      document.getElementById('error').classList.add('hidden');
    }

    function showError(msg) {
      document.getElementById('loading').classList.add('hidden');
      document.getElementById('error').classList.remove('hidden');
      document.getElementById('error-msg').textContent = msg;
    }

    function hideOverlays() {
      document.getElementById('loading').classList.add('hidden');
      document.getElementById('error').classList.add('hidden');
    }

    function addMessage(role, text) {
      const div = document.createElement('div');
      div.className = 'message ' + role;
      div.textContent = text;
      document.getElementById('messages').appendChild(div);
      document.getElementById('messages').scrollTop = 9999;
    }

    async function fetchToken() {
      const res = await fetch(backendUrl + '/api/heygen-token');
      if (!res.ok) throw new Error('Failed to get token');
      const data = await res.json();
      return data.token;
    }

    window.startAvatar = async function() {
      showLoading();

      try {
        const token = await fetchToken();
        console.log('Got token');

        avatar = new StreamingAvatar({ token });

        avatar.on(StreamingEvents.STREAM_READY, async (event) => {
          console.log('Stream ready');
          const video = document.getElementById('avatar-video');
          video.srcObject = event.detail;

          // Ensure audio plays by unmuting video element
          video.muted = false;
          video.volume = 1.0;

          video.play().catch(console.error);
          hideOverlays();

          document.getElementById('input').disabled = false;
          document.getElementById('send-btn').disabled = false;
          document.getElementById('mic-btn').disabled = false;

          // Greeting message
          const greeting = 'Hello ' + studentName + '! I\'m your AI Professor. I have context from the lecture, so just ask me anything!';
          addMessage('avatar', greeting);

          // Start audio pipeline immediately (don't wait for greeting to finish)
          // The speak queue handles interruption if user talks during greeting
          console.log('üé§ Starting audio pipeline...');
          startAudioPipeline();

          // Speak greeting (will be interrupted if user speaks first)
          isSpeakingResponse = true;
          await avatarSpeak(greeting);
          isSpeakingResponse = false;
        });

        avatar.on(StreamingEvents.STREAM_DISCONNECTED, () => {
          console.log('Disconnected');
          showError('Connection lost');
        });

        avatar.on(StreamingEvents.AVATAR_START_TALKING, () => {
          document.getElementById('speaking').classList.remove('hidden');
          console.log('üó£Ô∏è Avatar started talking');
        });

        avatar.on(StreamingEvents.AVATAR_STOP_TALKING, () => {
          document.getElementById('speaking').classList.add('hidden');
          console.log('üó£Ô∏è Avatar stopped talking (interrupted=' + _wasInterrupted + ')');

          if (!_wasInterrupted && isSpeakingResponse) {
            // Natural end of speech ‚Äî tell backend
            isSpeakingResponse = false;
            if (audioWs?.readyState === WebSocket.OPEN) {
              audioWs.send(JSON.stringify({ type: 'avatar_done' }));
            }
            updateVoiceStatus('listening');
          }
        });

        const session = await avatar.createStartAvatar({
          quality: AvatarQuality.Medium,
          avatarName: 'default',
        });

        console.log('Session started:', session);
        sessionId = session.session_id;

      } catch (err) {
        console.error('Full error:', err);
        console.error('Error details:', JSON.stringify(err, null, 2));
        showError(err.message || 'Failed to connect');
      }
    }

    window.sendMessage = async function() {
      const input = document.getElementById('input');
      const text = input.value.trim();
      if (!text || !avatar) return;

      input.value = '';
      addMessage('student', text);
      conversationHistory.push({ role: 'student', text });

      try {
        const llmRes = await fetch(backendUrl + '/api/tutor-response', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            message: text,
            student_name: studentName,
            history: conversationHistory
          })
        });

        let response;
        if (llmRes.ok) {
          const data = await llmRes.json();
          response = data.response;
        } else {
          response = 'Sorry, I had trouble processing that. Could you try again?';
        }

        addMessage('avatar', response);
        conversationHistory.push({ role: 'avatar', text: response });
        await avatarSpeak(response);
      } catch (err) {
        console.error('Speak error:', err);
      }
    }

    document.getElementById('input').addEventListener('keypress', (e) => {
      if (e.key === 'Enter') window.sendMessage();
    });

    // ============ VOICE PIPELINE (AudioWorklet ‚Üí Backend WebSocket ‚Üí Silero VAD + Deepgram nova-3) ============
    let isListening = false;
    let isSpeakingResponse = false;
    let isMuted = false;
    let audioWs = null;
    let audioContext = null;
    let audioWorkletNode = null;
    let mediaStream = null;

    function updateVoiceStatus(status) {
      const statusEl = document.getElementById('voice-status');
      const micBtn = document.getElementById('mic-btn');

      switch(status) {
        case 'listening':
          statusEl.textContent = 'üé§ Listening...';
          statusEl.style.background = 'rgba(59, 130, 246, 0.2)';
          statusEl.style.borderColor = 'rgba(59, 130, 246, 0.2)';
          statusEl.style.color = '#93c5fd';
          micBtn.classList.add('recording');
          break;
        case 'thinking':
          statusEl.textContent = 'ü§î Thinking...';
          statusEl.style.background = 'rgba(245, 158, 11, 0.2)';
          statusEl.style.borderColor = 'rgba(245, 158, 11, 0.2)';
          statusEl.style.color = '#fcd34d';
          micBtn.classList.remove('recording');
          break;
        case 'speaking':
          statusEl.textContent = 'üó£Ô∏è Speaking (interrupt anytime)';
          statusEl.style.background = 'rgba(59, 130, 246, 0.2)';
          statusEl.style.borderColor = 'rgba(59, 130, 246, 0.2)';
          statusEl.style.color = '#93c5fd';
          micBtn.classList.add('recording');
          break;
        case 'muted':
          statusEl.textContent = 'üîá Muted';
          statusEl.style.background = 'rgba(255, 255, 255, 0.04)';
          statusEl.style.borderColor = 'rgba(255, 255, 255, 0.06)';
          statusEl.style.color = 'rgba(255, 255, 255, 0.4)';
          micBtn.classList.remove('recording');
          break;
      }
    }

    // AudioWorklet processor with resampling support (data URI for Electron compat)
    const pcmProcessorCode = `
      class PCMProcessor extends AudioWorkletProcessor {
        constructor(options) {
          super();
          // Target: 512 samples at 16kHz (32ms chunks)
          this.targetRate = 16000;
          this.sourceRate = options.processorOptions?.sampleRate || sampleRate;
          this.ratio = this.sourceRate / this.targetRate;
          this.buffer = new Float32Array(512);
          this.bufferIndex = 0;
          this.srcIndex = 0; // fractional source index for resampling
        }
        process(inputs) {
          const input = inputs[0]?.[0];
          if (!input) return true;

          if (Math.abs(this.ratio - 1.0) < 0.01) {
            // No resampling needed (source is already 16kHz)
            for (let i = 0; i < input.length; i++) {
              this.buffer[this.bufferIndex++] = input[i];
              if (this.bufferIndex === 512) {
                this.port.postMessage(this.buffer.slice());
                this.bufferIndex = 0;
              }
            }
          } else {
            // Linear interpolation downsampling
            for (let i = 0; i < input.length; i++) {
              this.srcIndex += 1;
              while (this.srcIndex >= this.ratio) {
                this.srcIndex -= this.ratio;
                // Simple nearest-neighbor for speed
                this.buffer[this.bufferIndex++] = input[i];
                if (this.bufferIndex === 512) {
                  this.port.postMessage(this.buffer.slice());
                  this.bufferIndex = 0;
                }
              }
            }
          }
          return true;
        }
      }
      registerProcessor('pcm-processor', PCMProcessor);
    `;
    // Use data URI ‚Äî Blob URLs can fail in file:// or Electron contexts
    const processorDataUrl = 'data:application/javascript;base64,' + btoa(pcmProcessorCode);

    async function startAudioPipeline() {
      console.log('üé§ Starting audio pipeline...');

      try {
        // 1. Connect WebSocket to backend audio endpoint
        const wsUrl = backendUrl.replace('http', 'ws') + '/ws/audio';
        audioWs = new WebSocket(wsUrl);

        audioWs.onopen = () => {
          console.log('‚úÖ Audio WebSocket connected');
          audioWs.send(JSON.stringify({
            type: 'start_session',
            student_name: studentName,
            meeting_id: params.get('meeting_id'),
          }));
        };

        audioWs.onmessage = async (event) => {
          const data = JSON.parse(event.data);

          switch (data.type) {
            case 'interim_transcript':
              // Update input field with live transcription
              document.getElementById('input').value = data.text;
              break;

            case 'vad_speech_start':
              if (!isSpeakingResponse) {
                updateVoiceStatus('listening');
              }
              break;

            case 'vad_speech_end':
              // Backend processed: VAD end ‚Üí speculative LLM response
              console.log('üó£Ô∏è Got response:', data.response);

              addMessage('student', data.transcript);
              addMessage('avatar', data.response);
              conversationHistory.push({ role: 'student', text: data.transcript });
              conversationHistory.push({ role: 'avatar', text: data.response });
              document.getElementById('input').value = '';

              updateVoiceStatus('speaking');
              isSpeakingResponse = true;

              // Tell backend avatar is about to speak
              if (audioWs?.readyState === WebSocket.OPEN) {
                audioWs.send(JSON.stringify({ type: 'avatar_speaking' }));
              }

              // Fire-and-forget: avatar.speak() in async mode
              // Completion handled by AVATAR_STOP_TALKING event
              avatarSpeak(data.response);
              break;

            case 'interrupt_detected':
              // Backend VAD detected speech during avatar playback ‚Äî stop and listen
              console.log('‚ö° Interrupt detected ‚Äî stopping avatar');
              _wasInterrupted = true;
              isSpeakingResponse = false;
              try { await avatar.interrupt(); } catch(e) {}
              updateVoiceStatus('listening');
              break;

            case 'error':
              console.error('Backend error:', data.message);
              break;
          }
        };

        audioWs.onerror = (e) => {
          console.error('Audio WebSocket error:', e);
        };

        audioWs.onclose = (e) => {
          console.log('Audio WebSocket closed:', e.code);
          isListening = false;
          if (!isMuted) {
            console.log('üîÑ Reconnecting audio pipeline in 2s...');
            setTimeout(startAudioPipeline, 2000);
          }
        };

        // 2. Set up AudioWorklet for PCM capture (resample to 16kHz in worklet)
        audioContext = new AudioContext();
        console.log('AudioContext sample rate:', audioContext.sampleRate);
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          }
        });

        const source = audioContext.createMediaStreamSource(mediaStream);
        await audioContext.audioWorklet.addModule(processorDataUrl);
        audioWorkletNode = new AudioWorkletNode(audioContext, 'pcm-processor', {
          processorOptions: { sampleRate: audioContext.sampleRate }
        });

        // Convert float32 chunks to int16 and send via WebSocket
        audioWorkletNode.port.onmessage = (event) => {
          if (audioWs?.readyState !== WebSocket.OPEN || isMuted) return;
          const float32 = event.data;
          const int16 = new Int16Array(float32.length);
          for (let i = 0; i < float32.length; i++) {
            int16[i] = Math.max(-32768, Math.min(32767, Math.round(float32[i] * 32767)));
          }
          audioWs.send(int16.buffer);
        };

        source.connect(audioWorkletNode);
        // Connect to a silent destination to keep the worklet running
        audioWorkletNode.connect(audioContext.destination);

        isListening = true;
        updateVoiceStatus('listening');
        console.log('‚úÖ Audio pipeline started (16kHz PCM ‚Üí backend)');

      } catch (e) {
        console.error('‚ùå Failed to start audio pipeline:', e);
        updateVoiceStatus('muted');
      }
    }

    function stopAudioPipeline() {
      console.log('üõë Stopping audio pipeline...');
      isListening = false;

      if (audioWorkletNode) {
        audioWorkletNode.disconnect();
        audioWorkletNode = null;
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach(t => t.stop());
        mediaStream = null;
      }
      if (audioContext) {
        audioContext.close().catch(() => {});
        audioContext = null;
      }
      if (audioWs?.readyState === WebSocket.OPEN) {
        audioWs.close();
      }
      audioWs = null;
    }

    // Aliases for backward compat with explainer video code
    const startListening = startAudioPipeline;
    const stopListening = stopAudioPipeline;

    // Toggle mic button (mute/unmute)
    window.toggleMic = function() {
      if (isListening && !isMuted) {
        isMuted = true;
        stopAudioPipeline();
        updateVoiceStatus('muted');
        document.getElementById('mic-btn').textContent = 'üîá';
      } else {
        isMuted = false;
        document.getElementById('mic-btn').textContent = 'üé§';
        startAudioPipeline();
      }
    }

    // Start avatar and auto-enable voice
    window.startAvatar();

    // ============ EXPLAINER VIDEO HANDLING ============
    let currentExplainerJid = null;
    const explainerOverlay = document.getElementById('explainer-overlay');
    const explainerVideo = document.getElementById('explainer-video');
    const explainerTitle = document.getElementById('explainer-title');
    const explainerConcept = document.getElementById('explainer-concept');
    const continueBtn = document.getElementById('continue-btn');

    // Listen for play-explainer-video message from Electron main process
    // Since this is loaded with contextIsolation: false, we can use window events
    window.addEventListener('message', (event) => {
      if (event.data && event.data.type === 'play-explainer-video') {
        playExplainerVideo(event.data.payload);
      }
    });

    // Also listen via electron IPC if available
    if (typeof require !== 'undefined') {
      try {
        const { ipcRenderer } = require('electron');
        ipcRenderer.on('play-explainer-video', (event, payload) => {
          playExplainerVideo(payload);
        });
      } catch (e) {
        console.log('IPC not available, using postMessage');
      }
    }

    function playExplainerVideo(payload) {
      console.log('üé¨ Playing explainer video:', payload);

      const { concept, video_url, video_path, student_jid } = payload;
      currentExplainerJid = student_jid;

      // Update UI
      explainerTitle.textContent = 'Explainer: ' + (concept || 'Concept');
      explainerConcept.textContent = 'Watch this video to understand the concept better';

      // Determine video URL
      let videoSrc = video_url;
      if (!videoSrc && video_path) {
        // Use local file path
        videoSrc = video_path.startsWith('/') ? 'file://' + video_path : backendUrl + video_path;
      }

      if (!videoSrc) {
        console.error('No video source provided');
        addMessage('avatar', "Sorry, the explainer video isn't available right now.");
        notifyVideoCompleted();
        return;
      }

      // Pause avatar audio
      const avatarVideoEl = document.getElementById('avatar-video');
      if (avatarVideoEl) avatarVideoEl.muted = true;

      // Stop listening while watching video
      stopListening();

      // Show overlay and play video
      explainerVideo.src = videoSrc;
      explainerOverlay.classList.remove('hidden');
      continueBtn.classList.add('hidden');

      explainerVideo.play().catch(e => {
        console.error('Failed to play video:', e);
        addMessage('avatar', "Couldn't play the video. Let's continue.");
        hideExplainerAndContinue();
      });

      // Show continue button when video ends
      explainerVideo.onended = () => {
        console.log('üé¨ Explainer video ended');
        continueBtn.classList.remove('hidden');
      };

      explainerVideo.onerror = () => {
        console.error('Video error');
        addMessage('avatar', "There was an issue with the video. Let's continue.");
        hideExplainerAndContinue();
      };
    }

    window.skipExplainer = function() {
      console.log('‚è≠Ô∏è Skipping explainer video');
      explainerVideo.pause();
      hideExplainerAndContinue();
    };

    window.continueAfterExplainer = function() {
      console.log('‚û°Ô∏è Continuing after explainer');
      hideExplainerAndContinue();
    };

    function hideExplainerAndContinue() {
      explainerOverlay.classList.add('hidden');
      explainerVideo.pause();
      explainerVideo.src = '';

      // Unmute avatar
      const avatarVideoEl = document.getElementById('avatar-video');
      if (avatarVideoEl) avatarVideoEl.muted = false;

      // Notify backend that video is done
      notifyVideoCompleted();

      // Resume listening
      setTimeout(startListening, 500);
    }

    async function notifyVideoCompleted() {
      if (!currentExplainerJid) return;

      try {
        const response = await fetch(backendUrl + '/api/quiz/video-completed', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ student_jid: currentExplainerJid })
        });

        if (response.ok) {
          console.log('‚úÖ Notified backend video completed');
        }
      } catch (e) {
        console.error('Failed to notify video completion:', e);
      }

      currentExplainerJid = null;
    }
  </script>
</body>
</html>
